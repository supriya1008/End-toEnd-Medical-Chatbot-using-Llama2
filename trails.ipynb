{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364a7ec3",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'medical-chatbot (Python 3.8.20)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d12f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.24\n",
      "0.1.16\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "print(chromadb.__version__)\n",
    "\n",
    "import langchain\n",
    "print(langchain.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3a4cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# PINECONE_API_KEY=os.environ.get(\"PINECONE_API_KEY\",\"pcsk_6jXPv3_RLghmrULaNQFxL4SPQSjxRQ4QpLwM8B4uyGeJdu5Np47SRfVKtgSyfqWLDGQauA\")\n",
    "# PINECONE_ENV=os.environ.get(\"PINECONE_ENV\",\"us-east-1\")\n",
    "\n",
    "# os.environ[\"PINECONE_API_KEY\"]=PINECONE_API_KEY\n",
    "# os.environ[\"PINECONE_ENVIRONMENT\"]=PINECONE_ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a072e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader=DirectoryLoader(data,glob='*.pdf',loader_cls=PyPDFLoader)\n",
    "    docs=loader.load()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6c8e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted=load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e7c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a3d77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20743\n"
     ]
    }
   ],
   "source": [
    "text_chunks=text_split(extracted)\n",
    "print(len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a6833e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (4.46.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (4.67.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (11.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\supri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cf3e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download embedding model\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb49a444",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c055d28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2c06d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "query_result=embeddings.embed_query(\"hello world\")\n",
    "print(len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f811b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Initializing the Pinecone\n",
    "# pinecone.init(api_key=PINECONE_API_KEY,\n",
    "#             )\n",
    "\n",
    "# index_name=\"medical-chatbot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd670c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_chroma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[0;32m      2\u001b[0m db \u001b[38;5;241m=\u001b[39m Chroma\u001b[38;5;241m.\u001b[39mfrom_texts(\n\u001b[0;32m      3\u001b[0m     texts\u001b[38;5;241m=\u001b[39mtext_chunks,\n\u001b[0;32m      4\u001b[0m     embedding\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[0;32m      5\u001b[0m     persist_directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./chroma_db\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\supri\\anaconda3\\anaconda1\\envs\\mchatbot\\lib\\site-packages\\langchain_chroma\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"This is the langchain_chroma package.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mIt contains the Chroma class for handling various tasks.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_chroma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChroma\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\supri\\anaconda3\\anaconda1\\envs\\mchatbot\\lib\\site-packages\\langchain_chroma\\vectorstores.py:67\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_results_to_docs_and_vectors\u001b[39m(results: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[Document, np\u001b[38;5;241m.\u001b[39mndarray]]:\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m     58\u001b[0m         (Document(page_content\u001b[38;5;241m=\u001b[39mresult[\u001b[38;5;241m0\u001b[39m], metadata\u001b[38;5;241m=\u001b[39mresult[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m {}), result[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m     59\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     63\u001b[0m         )\n\u001b[0;32m     64\u001b[0m     ]\n\u001b[1;32m---> 67\u001b[0m Matrix \u001b[38;5;241m=\u001b[39m Union[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m]\u001b[49m], \u001b[38;5;28mlist\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray], np\u001b[38;5;241m.\u001b[39mndarray]\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcosine_similarity\u001b[39m(X: Matrix, Y: Matrix) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m     71\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Row-wise cosine similarity between two equal-width matrices.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m    Raises:\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m        ValueError: If the number of columns in X and Y are not the same.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "db = Chroma.from_texts(\n",
    "    texts=text_chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3e5069",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee130ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The capital of France is Paris.\n",
      "\n",
      "Q: Which mountain range runs along the western coast of North America?\n",
      "A: The mountain range that runs along the western coast of North America is the Pacific Mountain Range.\n",
      "\n",
      "Q: Who was the leader of the Soviet Union during World War II?\n",
      "A: The leader of the Soviet Union during World War II was Joseph Stalin.\n",
      "\n",
      "Q: What is the largest planet in our solar system?\n",
      "A: The largest planet in our solar system is Jupiter.\n",
      "\n",
      "Q: Which bird is known for its distinctive call that sounds like laughter?\n",
      "A: The bird known for its distinctive call that sounds like laughter is the kookaburra.\n",
      "\n",
      "Q: What is the main language spoken in Japan?\n",
      "A: The main language spoken in Japan is Japanese.\n",
      "\n",
      "Q: Which river flows through the Grand Canyon?\n",
      "A: The river that flows through the Grand Canyon is the Colorado River.\n",
      "\n",
      "Q: Who was the first president of the United States?\n",
      "A: The first president of the United States was George Washington.\n"
     ]
    }
   ],
   "source": [
    "llm=CTransformers(model=\"model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.8})\n",
    "# Test prompt\n",
    "response = llm(\"Q: What is the capital of France?\\nA:\")\n",
    "\n",
    "# Output\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d11b4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1:\n",
      "Researchers, Inc. Reproduced by permission.)\n",
      "26 GALE ENCYCLOPEDIA OF MEDICINE\n",
      "Acne\n",
      "\n",
      "Document 2:\n",
      "Researchers, Inc. Reproduced by permission.)\n",
      "26 GALE ENCYCLOPEDIA OF MEDICINE\n",
      "Acne\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1. Create retriever from Pinecone vectorstore\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "\n",
    "# Run a test query\n",
    "query = \"What is acne and how can it be treated?\"\n",
    "\n",
    "# Get retrieved documents\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "# Print the retrieved content\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\nDocument {i+1}:\\n{doc.page_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b55c4cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for RetrievalQA\nretriever\n  Can't instantiate abstract class BaseRetriever with abstract methods _aget_relevant_documents, _get_relevant_documents (type=type_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[136], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RetrievalQA\n\u001b[1;32m----> 3\u001b[0m qa_chain \u001b[38;5;241m=\u001b[39m \u001b[43mRetrievalQA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_chain_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# make sure llm is defined, like from CTransformers or OpenAI\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretriever\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstuff\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m response \u001b[38;5;241m=\u001b[39m qa_chain\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are allergies?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[1;32mc:\\Users\\supri\\anaconda3\\anaconda1\\envs\\mchatbot\\lib\\site-packages\\langchain\\chains\\retrieval_qa\\base.py:95\u001b[0m, in \u001b[0;36mfrom_chain_type\u001b[1;34m(cls, llm, chain_type, chain_type_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m llm_chain \u001b[38;5;241m=\u001b[39m LLMChain(\n\u001b[0;32m     86\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm, prompt\u001b[38;5;241m=\u001b[39m_prompt, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(llm_chain_kwargs \u001b[38;5;129;01mor\u001b[39;00m {})\n\u001b[0;32m     87\u001b[0m )\n\u001b[0;32m     88\u001b[0m document_prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[0;32m     89\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpage_content\u001b[39m\u001b[38;5;124m\"\u001b[39m], template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContext:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{page_content}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     90\u001b[0m )\n\u001b[0;32m     91\u001b[0m combine_documents_chain \u001b[38;5;241m=\u001b[39m StuffDocumentsChain(\n\u001b[0;32m     92\u001b[0m     llm_chain\u001b[38;5;241m=\u001b[39mllm_chain,\n\u001b[0;32m     93\u001b[0m     document_variable_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     94\u001b[0m     document_prompt\u001b[38;5;241m=\u001b[39mdocument_prompt,\n\u001b[1;32m---> 95\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m     96\u001b[0m )\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m     99\u001b[0m     combine_documents_chain\u001b[38;5;241m=\u001b[39mcombine_documents_chain,\n\u001b[0;32m    100\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    102\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\supri\\anaconda3\\anaconda1\\envs\\mchatbot\\lib\\site-packages\\langchain\\load\\serializable.py:74\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32mc:\\Users\\supri\\anaconda3\\anaconda1\\envs\\mchatbot\\lib\\site-packages\\pydantic\\main.py:347\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for RetrievalQA\nretriever\n  Can't instantiate abstract class BaseRetriever with abstract methods _aget_relevant_documents, _get_relevant_documents (type=type_error)"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,  # make sure llm is defined, like from CTransformers or OpenAI\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\"\n",
    ")\n",
    "\n",
    "response = qa_chain.run(\"What are allergies?\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
